{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3, Wrangle OpenStreetMap Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Area\n",
    "\n",
    "For this project, I chose where I currently live - San Mateo, California. It is in the middle of the Bay Area, and also a very quiet place to live. I want to see everything this city has to offer.\n",
    "\n",
    "Link to San Mateo coordinates and download on OSM - [https://www.openstreetmap.org/export#map=13/37.5572/-122.3149](https://www.openstreetmap.org/export#map=13/37.5572/-122.3149)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Audit / Quick Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the XML File\n",
    "\n",
    "#### Looking at the XML file, there are different tags such as \"nodes\" and \"ways\". Here's a list of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bounds': 1,\n",
       " 'member': 10857,\n",
       " 'meta': 1,\n",
       " 'nd': 701309,\n",
       " 'node': 618225,\n",
       " 'note': 1,\n",
       " 'osm': 1,\n",
       " 'relation': 882,\n",
       " 'tag': 139074,\n",
       " 'way': 71557}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafile = 'map'\n",
    "\n",
    "def count_tags(filename):\n",
    "    tagsDict = {}\n",
    "    for event, element in ET.iterparse(filename):\n",
    "        if element.tag not in tagsDict.keys():\n",
    "            tagsDict[element.tag] = 1\n",
    "        else:\n",
    "            tagsDict[element.tag] += 1\n",
    "\n",
    "    return tagsDict\n",
    "    print tagsDict\n",
    "    \n",
    "count_tags(datafile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Looking at the \"K\" attribute values in the XML file, we can see whether the attributes are okay or problematic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 102700, 'lower_colon': 34753, 'other': 1621, 'problemchars': 0}\n"
     ]
    }
   ],
   "source": [
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        # YOUR CODE HERE\n",
    "        lower_re = lower.search(element.attrib['k'])\n",
    "        lower_colon_re = lower_colon.search(element.attrib['k'])\n",
    "        problemchars_re = problemchars.search(element.attrib['k'])\n",
    "        if lower_re:\n",
    "            keys[\"lower\"] += 1\n",
    "        elif lower_colon_re:\n",
    "            keys[\"lower_colon\"] += 1        \n",
    "        elif problemchars_re:\n",
    "            keys[\"problemchars\"] += 1\n",
    "        else:\n",
    "            keys['other'] += 1\n",
    "    return keys\n",
    "\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys\n",
    "\n",
    "pprint.pprint(process_map(datafile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Problems Encountered in the Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The main issue I encountered in the OpenStreetMap dataset is that the street and postal codes are not consistent from user to user.\n",
    "\n",
    "In this part of the project, I will use Audit.py to audit and clean abbreviated and incorrect street names as well as postal codes. I will replace street abbreviations like \"St.\", \"Blvd\", \"Ave.\", Rd\" to their full name - \"Street\", \"Boulevard\", \"Avenue\", and \"Road\". In the Audit.py file, I take the following steps:\n",
    "\n",
    "* Create a list of expected street types that do not need to be cleaned\n",
    "* If the last word of a street name does not match one of the expected street types, I store that entry in a dictionary\n",
    "* Once I have a dictionary of street names that are unexpected, I use the update_name function to update the unexpected names to new names that make sense\n",
    "\n",
    "I did similar things to validate the postal codes. If a postal code is not a 5 digit number, I use the update_postcode function to fix them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick examples of the inconsistencies and their fixes, using Audit.py file:\n",
    "\n",
    "* Rollins Rd => Rollins Road\n",
    "* Granada St => Granada Street\n",
    "* Leslie => Leslie Street\n",
    "* 94002-2121 => 94002\n",
    "* 944023025 => 94402"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Prepare to Import Data to Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The next step is to prepare data to be inserted into a database, using P3_Data_Prep.py file\n",
    "\n",
    "* Once the OSM data transformed into csv files, I can load it into the sqlite database, using database.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Statistical Overview of the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The map file is 131.760241 MB\n",
      "The nodes.csv file is 52.755535 MB\n",
      "The nodes_tags.csv file is 0.415798 MB\n",
      "The ways.csv file is 4.312471 MB\n",
      "The ways_tags.csv file is 4.243671 MB\n",
      "The ways_nodes.csv file is 16.855967 MB\n",
      "The project3.db file is 88.997888 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print 'The map file is {} MB'.format(os.path.getsize('map')/(10.**6))\n",
    "print 'The nodes.csv file is {} MB'.format(os.path.getsize('nodes.csv')/(10.**6))\n",
    "print 'The nodes_tags.csv file is {} MB'.format(os.path.getsize('nodes_tags.csv')/(10.**6))\n",
    "print 'The ways.csv file is {} MB'.format(os.path.getsize('ways.csv')/(10.**6))\n",
    "print 'The ways_tags.csv file is {} MB'.format(os.path.getsize('ways_tags.csv')/(10.**6))\n",
    "print 'The ways_nodes.csv file is {} MB'.format(os.path.getsize('ways_nodes.csv')/(10.**6))\n",
    "print 'The project3.db file is {} MB'.format(os.path.getsize('project3.db')/10.**6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Unique Users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(407,)]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "sqlite_file = 'project3.db'\n",
    "con = sqlite3.connect(sqlite_file)\n",
    "cur = con.cursor()\n",
    "\n",
    "cur.execute(\"SELECT COUNT(DISTINCT(e.uid)) FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) e;\")\n",
    "print cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Nodes and Ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: [(618225,)]\n",
      "Ways: [(71557,)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT count(*) FROM nodes\")\n",
    "print \"Nodes: {}\".format(cur.fetchall())\n",
    "cur.execute(\"SELECT COUNT(*) FROM ways\")\n",
    "print \"Ways: {}\".format(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10 Contributing Users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'abel801', 97168),\n",
      " (u'calfarome', 55721),\n",
      " (u'nikhilprabhakar', 46554),\n",
      " (u'Luis36995', 44129),\n",
      " (u'RichRico', 43368),\n",
      " (u'samely', 35351),\n",
      " (u'dannykath', 35123),\n",
      " (u'Jothirnadh', 34874),\n",
      " (u'saikabhi', 33000),\n",
      " (u'karitotp', 32934)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT e.user, COUNT(*) AS num FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e \\\n",
    "            GROUP BY e.user ORDER BY num DESC LIMIT 10;\")\n",
    "pprint.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Amenities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'restaurant', 135),\n",
      " (u'school', 56),\n",
      " (u'bench', 53),\n",
      " (u'place_of_worship', 43),\n",
      " (u'fast_food', 38),\n",
      " (u'cafe', 34),\n",
      " (u'toilets', 30),\n",
      " (u'fuel', 29),\n",
      " (u'bank', 27),\n",
      " (u'atm', 16)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT value, COUNT(*) AS num FROM nodes_tags WHERE key='amenity' \\\n",
    "            GROUP BY value ORDER BY num DESC LIMIT 10;\")\n",
    "pprint.pprint(cur.fetchall())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popular Cuisines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'japanese', 12),\n",
      " (u'mexican', 12),\n",
      " (u'chinese', 11),\n",
      " (u'italian', 10),\n",
      " (u'pizza', 10),\n",
      " (u'asian', 6),\n",
      " (u'burger', 3),\n",
      " (u'greek', 2),\n",
      " (u'indian', 2),\n",
      " (u'sushi', 2),\n",
      " (u'vietnamese', 2),\n",
      " (u'Persian', 1),\n",
      " (u'Salad,_Sandwiches,_Juice_Bars_&_Smoothies', 1),\n",
      " (u'american', 1),\n",
      " (u'breakfast_brunch_french', 1),\n",
      " (u'crepe;sandwich;breakfast', 1),\n",
      " (u'filipino', 1),\n",
      " (u'fondue', 1),\n",
      " (u'hawaiian', 1),\n",
      " (u'ice_cream', 1),\n",
      " (u'international', 1),\n",
      " (u'japanese;korean', 1),\n",
      " (u'korean', 1),\n",
      " (u'mediterranean;middle_eastern', 1),\n",
      " (u'pancake', 1),\n",
      " (u'regional', 1),\n",
      " (u'sandwich', 1),\n",
      " (u'seafood', 1),\n",
      " (u'thai', 1)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT value,COUNT(*) AS num FROM nodes_tags JOIN (SELECT DISTINCT(id) \\\n",
    "            FROM nodes_tags WHERE value = 'restaurant') i ON nodes_tags.id = i.id\\\n",
    "            WHERE nodes_tags.key='cuisine'\\\n",
    "            GROUP BY nodes_tags.value\\\n",
    "            ORDER BY num DESC;\")\n",
    "pprint.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OpenStreetMap data for San Mateo, California is quite an accomplishment that was achieved through having users contribute to the open source data. However, it is clear that the area is not complete nor very accurate. For example, in the \"Popular Cuisines\" query, Japanese Cuisines appeared multiple times - \"japanese\", \"sushi\", and \"japanese;korean\". I think a more standardized data entry should be implemented.\n",
    "\n",
    "Also, based on the procedures to cleaning streets and postal codes, I noticed that not all streets are there, while others are either spelled wrong or have different variations of a single location.\n",
    "\n",
    "## Suggestions:\n",
    "* Have local business owners enter/edit their own locational data, since they have an incentive to keep their address and descriptions as accurate as possible\n",
    "* Encourage more people to use OpenStreetMap and contribute to its content, will ensure a more complete picture of certain areas\n",
    "* Build parsers or have designated moderators set regular cadence to check for data accuracy like street and zipcode inputs\n",
    "\n",
    "### Benefits:\n",
    "* If more people contribute to OpenStreetMap, then the user base will grow, and the data will be more complete, and we can have an true open source map that can be scraped and analyzed more easily\n",
    "* If the data is more accurate, more people are inclined to use OpenStreetData and pay visits to the amenities, and thus generate more revenue for the city through tourism\n",
    "\n",
    "### Anticipated Problems:\n",
    "* OpenStreetMap is open source, which comes with the downside of not having paid employee to keep the data quality in check. Even if there are volunteer moderators to check the data every once in a while, there is no guarantee that the data is going to be clean and completely reliable\n",
    "* It will take some time to truly get people to use and contribute to OpenStreetMap, since there are much better apps like Google Map. Awareness is key here. With such popularity, Google map almost completely overshadows OpenStreetMap, which means the general public and businesses most likely will not adopt OpenStreetMap as their primary source of locational data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
